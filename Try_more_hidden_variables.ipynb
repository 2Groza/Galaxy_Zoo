{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import keras.layers.advanced_activations\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import norm  \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import VarianceScaling,RandomNormal\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Reshape, Lambda, Flatten, Activation\n",
    "from keras.models import Model  \n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras import backend as K  \n",
    "from keras import objectives  \n",
    "from keras.utils.vis_utils import plot_model  \n",
    "from keras.utils import np_utils, generic_utils\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sklearn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "from sklearn import manifold, datasets,cluster\n",
    "from sklearn.utils import check_random_state\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.listdir('cstor/xsede/users/xs-haosun/SDSS_2000/')\n",
    "\n",
    "Obj_ID = []\n",
    "Image = []\n",
    "Class = []\n",
    "Redshift = []\n",
    "for i in range(len(path)):\n",
    "    path_now = path[i]\n",
    "    a = np.load('cstor/xsede/users/xs-haosun/SDSS_2000/'+str(path_now))\n",
    "    for j in range(a.shape[0]):\n",
    "        Obj_ID.append(a[j]['objID'])\n",
    "        Image.append(a[j]['image'])\n",
    "        Class.append(a[j]['class'])\n",
    "        Redshift.append(a[j]['z'])\n",
    "\n",
    "Obj_ID = np.asarray(Obj_ID)\n",
    "Image = np.asarray(Image)\n",
    "Class = np.asarray(Class)\n",
    "Redshift = np.asarray(Redshift)\n",
    "Class[Class=='STAR'] = 0\n",
    "Class[Class=='GALAXY'] = 1\n",
    "Class[Class=='QSO'] = 2\n",
    "Class = Class.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_RGB = np.empty((len(Image),64,64))#(14142,64,64,1) one channel images\n",
    "for i in range(len(Image)):\n",
    "    #b[i] = np.stack((a[i][1][0],a[i][1][1],a[i][1][2],a[i][1][3],a[i][1][4]),axis=-1)\n",
    "    Image_RGB[i] = Image[i][2]\n",
    "\n",
    "\n",
    "for i in range(len(Image_RGB)):\n",
    "    if True in np.isnan(Image_RGB[i]).reshape(64*64*1):\n",
    "        print(i)\n",
    "        Image_RGB[i][np.isnan(Image_RGB[i])==True]=np.mean(Image_RGB[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image_RGB =(1- ( (Image_RGB - np.min(Image_RGB))/(np.max(Image_RGB) - np.min(Image_RGB))))*2 - 1\n",
    "\n",
    "Image_RGB /= np.max(Image_RGB)\n",
    "Image_RGB -= np.mean(Image_RGB)\n",
    "Image_RGB = -Image_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (14142, 64, 64, 1)\n",
      "train_label.shape: (14142, 3)\n"
     ]
    }
   ],
   "source": [
    "label = np_utils.to_categorical(Class, 3)\n",
    "data = Image_RGB.reshape(-1,64,64,1)\n",
    "index = [i for i in range(len(data))]\n",
    "#random.shuffle(index)\n",
    "train_data = data[index]\n",
    "train_label = label[index]\n",
    "#Class = Class[index]\n",
    "#Redshift = Redshift[index]\n",
    "#show_Image_RGB = show_Image_RGB[index]\n",
    "print('train_data.shape:',train_data.shape)\n",
    "print('train_label.shape:',train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "latent_dim = 30\n",
    "nb_epoch = 50  \n",
    "epsilon_std =1.0\n",
    "intermediate_dim_1 = 600\n",
    "#intermediate_dim_2 = 300\n",
    "original_dim = 64*64\n",
    "\n",
    "input_img = Input(shape=(64,64,1))\n",
    "\n",
    "conv_1 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(input_img)\n",
    "maxpool_1 = MaxPooling2D((2, 2),  padding='same')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(maxpool_1)\n",
    "maxpool_2 = MaxPooling2D((2, 2),  padding='same')(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(maxpool_2)\n",
    "maxpool_3 = MaxPooling2D((2, 2),  padding='same')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(maxpool_3)\n",
    "#maxpool_4 = MaxPooling2D((2, 2),  padding='same')(conv_4)\n",
    "\n",
    "#conv_5 = Conv2D(80, (3, 3), activation='tanh', padding='same',kernel_initializer='normal')(maxpool_4)\n",
    "#maxpool_5 = MaxPooling2D((2, 2),  padding='same')(conv_5)\n",
    "\n",
    "#x = Conv2D(5, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(x)\n",
    "#x = MaxPooling2D((2, 2),  padding='same')(x)\n",
    "\n",
    "visual = Flatten()(conv_4)\n",
    "h_1 = Dense(intermediate_dim_1, activation='relu')(visual)\n",
    "#h_2 = Dense(intermediate_dim_2, activation='tanh')(h_1)\n",
    "\n",
    "z_mean = Dense(latent_dim)(h_1)\n",
    "z_log_var = Dense(latent_dim)(h_1)\n",
    "\n",
    "def sampling(args):   \n",
    "    z_mean, z_log_var = args  \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2)* epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "#h_3 = Dense(intermediate_dim_2,activation='tanh')(z)\n",
    "h_4 = Dense(intermediate_dim_1,activation='tanh')(z)\n",
    "h_5 = Dense(80*8*8,activation='relu')(h_4)\n",
    "h_6 = Reshape((8,8,80))(h_5)\n",
    "\n",
    "\n",
    "#conv_6 = Conv2D(80, (3, 3), activation='tanh', padding='same',kernel_initializer='normal')(h_6)\n",
    "#upsample_6 = UpSampling2D((2, 2))(conv_6)\n",
    "\n",
    "conv_7 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(h_6)\n",
    "#upsample_7 = UpSampling2D((2, 2))(conv_7)\n",
    "\n",
    "conv_8 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(conv_7)\n",
    "upsample_8 = UpSampling2D((2, 2))(conv_8)\n",
    "\n",
    "conv_9 = Conv2D(80, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(upsample_8)\n",
    "upsample_9 = UpSampling2D((2, 2))(conv_9)\n",
    "\n",
    "conv_10 = Conv2D(80,  (3, 3), activation='tanh',padding='same',kernel_initializer='normal')(upsample_9)\n",
    "upsample_10 = UpSampling2D((2, 2))(conv_10)\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(upsample_10)\n",
    "\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "def vae_loss(x, decoded):  \n",
    "    xent_loss = K.sum(K.sum(objectives.binary_crossentropy(x ,decoded),axis=-1),axis=-1)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) \n",
    "    return xent_loss + 1*kl_loss  \n",
    "\n",
    "\n",
    "vae = Model(inputs=input_img, outputs=decoded)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "14000/14000 [==============================] - 31s - loss: 1.8875 - val_loss: -54.4998\n",
      "Epoch 2/5\n",
      "14000/14000 [==============================] - 30s - loss: -72.2160 - val_loss: -60.9372\n",
      "Epoch 3/5\n",
      "12700/14000 [==========================>...] - ETA: 2s - loss: -79.3405"
     ]
    }
   ],
   "source": [
    "vae.fit(train_data[:14000], train_data[:14000],\n",
    "        shuffle=True,\n",
    "        epochs=5,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(train_data[14000:14100],train_data[14000:14100]),callbacks=[EarlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "\n",
    "decoded_imgs = vae.predict(train_data[8000:9500],batch_size=100)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2,n,i)\n",
    "    plt.imshow((train_data[8000:9500][i][:,:,0]))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n ,i + n)\n",
    "    plt.imshow((decoded_imgs[i][:,:,0]))\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae.save_weights(\"no_distortion0810.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
